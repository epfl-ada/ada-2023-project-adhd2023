{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE BERT MODEL AND DEFINE HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-Large-cased')\n",
    "model = BertModel.from_pretrained('bert-large-cased')\n",
    "\n",
    "# Function to tokenize and encode text\n",
    "def encode(text, max_length=512):\n",
    "    # Subtract 2 for [CLS] and [SEP] tokens\n",
    "    if len(text) == 0:\n",
    "        print(\"Empty text\")  # Debugging\n",
    "    \n",
    "    max_length -= 2\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) == 0:\n",
    "        print(\"Empty tokens\")  # Debugging\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    if not chunks:  # Check if chunks are empty\n",
    "        print(f\"No chunks for text: {text}\")  # Debugging\n",
    "\n",
    "    # Process each chunk\n",
    "    chunk_embeddings = []\n",
    "    for chunk in chunks:\n",
    "        # Add special tokens\n",
    "        chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(chunk)\n",
    "        input_tensor = torch.tensor([input_ids]).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_tensor)[0]  # Get the embeddings\n",
    "        chunk_embeddings.append(last_hidden_states[0].mean(dim=0))\n",
    "\n",
    "    # Aggregate the embeddings from each chunk (mean pooling here)\n",
    "    embeddings = torch.mean(torch.stack(chunk_embeddings), dim=0)\n",
    "    return embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/c4f8zf_14lg_474m69nfgc7m0000gn/T/ipykernel_54624/3539005712.py:31: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  name_id_df = pd.read_csv('data/name_id.tsv',  sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20160, 2)\n",
      "(20160, 10)\n"
     ]
    }
   ],
   "source": [
    "# Read datasets\n",
    "events = pd.read_csv('data/events.csv')\n",
    "#convert the year column to int\n",
    "events['Year'] = events['Year'].astype(int)\n",
    "\n",
    "\n",
    "#read tsv file and add headers\n",
    "movie_metadata_df = pd.read_csv('data/movie.metadata.tsv', sep='\\t', header=None, \n",
    "                names=['wiki_movie_id', \n",
    "                        'freebase_movie_id', \n",
    "                        'movie_name', \n",
    "                        'movie_release_date', \n",
    "                        'movie_box_office_revenue', \n",
    "                        'movie_runtime', \n",
    "                        'movie_languages', \n",
    "                        'movie_countries', \n",
    "                        'movie_genres'])\n",
    "\n",
    "#changing the values of outliers\n",
    "movie_metadata_df.loc[movie_metadata_df['movie_name'] == 'Zero Tolerance', 'movie_runtime'] = 88\n",
    "movie_metadata_df.loc[movie_metadata_df['movie_name'] == 'Hunting Season', 'movie_release_date'] = '2010-12-02'\n",
    "\n",
    "#add realase_year \n",
    "movie_metadata_df['startYear']= movie_metadata_df['movie_release_date'].str[:4]\n",
    "\n",
    "#change movie_release_date to pandas datetime\n",
    "movie_metadata_df['movie_release_date'] = pd.to_datetime(movie_metadata_df['movie_release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "#load IMDB reviews\n",
    "rating_id_df = pd.read_csv('data/rating_id.tsv',  sep='\\t')\n",
    "name_id_df = pd.read_csv('data/name_id.tsv',  sep='\\t')\n",
    "rating_df = pd.merge(rating_id_df, name_id_df, on='tconst')\n",
    "\n",
    "#drop unnecessary columns \n",
    "rating_df.drop(['originalTitle','isAdult','endYear','runtimeMinutes','genres'], axis=1, inplace=True)\n",
    "\n",
    "#loading the plot summaries dataset and add headers\n",
    "plot_summaries_df = pd.read_csv('data/plot_summaries.txt', sep='\\t', header=None, \n",
    "                names=['wiki_movie_id', \n",
    "                        'plot_summary'])\n",
    "#merging the movie metadata with the rating data on movie name and release year\n",
    "movies_ratings = pd.merge(movie_metadata_df, rating_df,  on=['movie_name', 'startYear'])\n",
    "movies_ratings.shape\n",
    "\n",
    "# printing the types of the merged data \n",
    "movies_ratings['titleType'].unique()\n",
    "\n",
    "#remove any {{ }} from the plot summary text\n",
    "plot_summaries_df['plot_summary'] = plot_summaries_df['plot_summary'].str.replace(r'\\{\\{.*?\\}\\}', '', regex=True)\n",
    "\n",
    "# remove all summaries with length = 0\n",
    "plot_summaries_df = plot_summaries_df[plot_summaries_df['plot_summary'].str.len() > 0]\n",
    "\n",
    "# keeping only movies, delete tv episodes, tv movies, video games, etc.\n",
    "movies_ratings = movies_ratings[movies_ratings['titleType']=='movie']\n",
    "\n",
    "\n",
    "# only keep the movies with more than 100 votes on imdb ratings\n",
    "movies_ratings = movies_ratings[movies_ratings['numVotes']>200]\n",
    "movies_ratings.shape\n",
    "\n",
    "#keep movie_metadata_df only with movies that have ratings\n",
    "movie_metadata_df = movie_metadata_df[movie_metadata_df['freebase_movie_id'].isin(movies_ratings['freebase_movie_id'])]\n",
    "movie_metadata_df.shape\n",
    "\n",
    "#keep the summaries of the selected movies \n",
    "plot_summaries_df = plot_summaries_df[plot_summaries_df['wiki_movie_id'].isin(movie_metadata_df['wiki_movie_id'])]\n",
    "print(plot_summaries_df.shape)\n",
    "\n",
    "#keep movie_metadata_df only with movies that have summaries\n",
    "movie_metadata_df = movie_metadata_df[movie_metadata_df['wiki_movie_id'].isin(plot_summaries_df['wiki_movie_id'])]\n",
    "print(movie_metadata_df.shape)\n",
    "\n",
    "# save the cleaned summary dataset\n",
    "plot_summaries_df.to_csv('data/plot_summaries_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE EVENT DESCRIPTION EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, encode, and get embeddings\n",
    "events['Embeddings'] = events['Event Description'].apply(lambda x: encode(x).tolist() if pd.notnull(x) else None)\n",
    "#save the embeddings of events as a csv file\n",
    "events.to_csv('data/events_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE MOVIE SUMMARY PLOT EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the plot_summaries_df with embedding of the summary\n",
    "plot_summaries_df['Embeddings'] = plot_summaries_df['plot_summary'].apply(lambda x: encode(x).tolist() if pd.notnull(x) else None)\n",
    "\n",
    "#save the embeddings of summaries as a csv file\n",
    "plot_summaries_df.to_csv('data/plot_summaries_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
